日拱一卒

count(1)、count(*)和count(field)的区别？
执行效果：count(*)统计表中所有的列，包括NULL

		  count(1)统计表中不为NULL的列

		  count(field)统计表中field不为NULL的列

	测试结果：效率(18M数据)：count(*) > count(1) >= count(id)



MVCC是什么？
MVCC是MySQL中用于处理**读写冲突**，以无锁的方式提高读写并发能力的一种机制，其通过3个隐式字段、undo log和read view实现。将同一个数据分为多个版本，在读写时读写不同的版本避免冲突(读较早版本，写较新版本)。

	MVCC为事务分配了单向增长的时间戳(版本号)，每次修改都保存一个版本，读操作只能读取事务开始前的数据库快照。

**隐式字段**

	数据库中除了自定义字段外，额外包涵隐式定义的`DB_TRX_ID`，`DB_ROLL_PTR `，`DB_ROW_ID `。DB_TRX_ID记录最近修改的事务id；DB_ROLL_PTR为回滚指针，指向上一个版本的数据；DB_ROW_ID为自增id，若表没有主键会自动以DB_ROW_ID构建聚簇索引。

**undo log**

	Undo log主要分为insert undo log和update undo log，分别用于记录插入操作和更新操作前的信息，当需要回滚时，根据undo log信息即可完成数据恢复。DB_ROLL_PTR回滚指针即指向undo log中的数据，用于查询较早版本。

**read view**

	Read view是在事务进行快照读时产生的读视图，这个读视图会维护系统当前的活跃事务的id，通过这些活跃id和当前事务id即可判断当前事务可以读取哪个版本的数据(使用可见性算法判断)。参考：https://zhuanlan.zhihu.com/p/500868047



Java中boolean的长度？boolean[]中元素的长度？
JVM规范并未详细规定boolean的具体实现方式，其本质仅包含一个bit的信息，但由于内存对齐等因素采用8bit实现能够优化访存效率。

	在HotSpot中，使用int类型实现单个的boolean变量，因此一个boolean变量占用4字节；对于boolean[]类型，使用byte[]的方式实现，因此boolean[]内一个元素占用1个字节。



三色标记法？
三色标记法是CMS和G1收集器使用的垃圾标记算法，其将全部的对象划分为黑、灰、白三色用以区分标记状态。

	黑色：有用的对象，其本身及其引用的对象都被标记过了，不会被回收；

	灰色：有用的对象，其本身被标记过了但其引用的对象尚未完全标记，这是一种中间状态；

	白色：将被回收的对象，表示该对象不可达。

	算法具体流程如下：

	① 将全部对象放入白色集合中，等待标记；

	② 从GC root开始遍历对象(非递归遍历)，将被访问到的对象放入灰色集合，该阶段需要STW；

	③ 遍历灰色集合中的对象(递归遍历)，将被访问到的对象放入灰色集合，遍历完后将该对象放入黑色集合中，表示遍历完成，该阶段为并发标记；

	④ 重复步骤③直至灰色集合为空；

	⑤ 回收所有白色集合中的对象，完成GC标记清理。

	

	三色标记法存在两个问题：

	① 浮动垃圾：上述步骤③为并发标记过程，用户线程运行可能导致原本标记为黑色的对象被取消引用，变为无效对象。这种情况三色标记法无法识别，导致黑色集合中出现浮动垃圾。浮动垃圾在数量不多的情况下影响不大，下次GC即可清除。

	② 漏标对象(错误回收)：同样由于并发标记，原本标记为黑色的对象重新引用白色对象，由于黑色对象不会参与遍历，因此白色对象不会被标记，导致白色对象被错误回收。

	解决方案：

	CMS使用增量更新的方法解决漏标的问题。当一个黑色(或灰色)对象重新引用白色对象时，则将黑色对象变为灰色，使之可以重新被遍历以发现其引用的白色对象。注：该方法仍有漏洞，若灰色对象引用白色对象时，该灰色对象正在被标记，标记完成后会被转为黑色对象，不会触发褪色，导致漏标。因此增量更新处于CMS的重新标记阶段，该阶段需要STW。

	G1使用SATB(初始快照)的方式解决漏标问题。在并发标记时若出现引用失效，会记录一个引用消失前的快照，GC时依照快照进行删除，将新出现的白色对象变为浮动垃圾，等待下一次GC清除。G1本质上是使用一种保守删除的方式，避免出现误删。



	5. 进程间通信方式

	狭义上的进程通信是进程之间进行数据传输，广义上来说进程之间的协作和同步也属于进程通信，因此处理进程同步的信号量机制、锁机制可以作为一种通信方式。

	此外，进程间数据传输包含五种方式，分别为：管道、共享内存、消息队列、信号、套接字(网络通信)。

	① 管道：管道存在于内存中，其本质是一块内核缓冲区，管道可以分为匿名管道和命名管道。匿名管道为半双工通信，具备固定的读端和写端，数据在某一时刻仅能单向传输，且仅能在具有亲缘关系的进程(父子进程)间使用。命名管道(fifo)可以在无亲缘关系的进程间实现通信。通过一个名称绑定一个缓冲区，不同进程通过名称即可访问相同的缓冲区实现通信。

	② 共享内存：共享内存是允许多个进程将同一片物理内存连接至自己的内存空间，使多个进程可以访问相同的内存区域。共享内存通过页表实现，多个线程的虚拟内存(逻辑地址)通过页表映射到同一片物理内存，即可实现内存共享。由于共享内存后，进程以普通的访存方式进行数据交换，不涉及内核和数据复制，因此效率较高。

	③ 消息队列：消息队列本质上是一个存放于内核中的链表，消息的消费者和生产者通过在表头和表尾拿取和生成数据，即可完成不同线程间的通信。由于消息队列存在于内核中，生产和消费数据时涉及数据拷贝，因此效率较共享内存低。

	④ 信号：信号是向某个进程发送指定的信号，中断进程执行并告知进程执行特定操作，完成操作后再继续恢复执行(或终止)。信号可以来源于硬件源和软件源。

	⑤ 套接字(Socket)：套接字是可以用做不同主机间进程通信的方式，其本身也是计算机网络的基础。其基于TCP/IP协议族进行网络通信，通过协议、本机ip、本机端口、目的ip、目的端口五元组定义一个通信连接，实现进程通信。

参考：https://zhuanlan.zhihu.com/p/465574868



	6. 软连接和硬连接的区别

	Linux下有软连接和硬连接两种文件连接方式，使用ln A B命令可以建立一个连接文件B，连接至文件A，默认为硬连接；使用ln -s A B可以建立起B->A的软连接。

	硬连接本质上是磁盘上文件的别名，其与原文件地位相等，拥有相同的inode号。当所有硬连接(包括最初文件)被删除后，磁盘文件会被删除。

	软连接本质上是建立了一个新的连接文件，连接文件引用到原文件，删除所有的软连接文件时，原文件不受影响。



	7. linux 常用指令

	① wc指令，word count用于统计文件内的字符统计

	  -l 或—list：统计文件行数

	  -w 或 —words：统计文件单词数目或字数

	  -c 或 —chars 或 —bytes：统计文件内的字符个数

	  例如： wc -l test.txt 输出文件的行数

	

	② vi处于Insert模式中，Esc键无法退出时，使用Ctrl+c键退出Insert模式，再退出。

	

	③ netstat执行，查看网络状态

	  -t	显示tcp端口

	  -u	显示udp端口

	  -l	显示listen监听状态下的套接字

	  -p显示进程id和进程名称

	  -n显示数字形式的IP地址和端口号

	  -a显示所有连接和监听端口

	  -o显示当前用户拥有的套接字信息

	

	④ lsof List Open File，查看被打开的文件信息。由于Linux中一切皆文件，普通文件、管道、套接字、设备等都可以通过该指令查询。

	  -I 查看打开的套接字，I为internet首字母。 -i:port查看指定端口打开的文件；-i TCP/UDP查看使用了TCP或UDP协议的文件。



8. redo log、undo log、 bin log写入顺序

   undo log -> redo log -> bin log

   ① undo log(回滚日志)——事务原子性

   undo log的存在是为了维护事务的原子性和MVCC。在事务执行的过程中，进行每次写操作(insert和update)时都会先将原始数据写入undo buffer，再对数据进行操作，确保原始数据的完整。当事务提交后再将undo buffer中的内容持久化为undo log。在这个过程中若其他事务希望读取数据会通过MVCC机制获取undo buffer内的原始数据快照，保证事务隔离。

   当需要回滚时，通过读取undo log即可恢复原始数据信息，保证事务原子性。

   回滚段与undo段的细节。



	② redo log(重做日志)——持久性

	redo log是innodb数据引擎实现持久化的方式。数据库会维护一个redo log buffer，用于记录对数据页的修改，当触发刷盘条件，再将缓存中的数据写入磁盘进行持久化。Mysql使用innodb_flush_log_at_trx_commit参数定义刷盘的策略，该参数有三个取值：0、1、2，Mysql默认值为1。

	取0时，innodb引擎每隔一秒进行一次刷盘操作，服务器宕机可能会丢失1秒内的数据，这种情况事务提交时不做持久化。

	取1时，每隔一秒刷盘一次以外，每次提交事务也会进行刷盘操作，理论上不会丢失数据。未提交事务，本就是中间数据，不计入损失。

	取2时，每隔一秒刷盘一次，此外每次提交事务将redo log缓存写入系统文件缓存，等待每秒轮询从系统文件缓存刷盘。数据库崩溃不会丢失数据，服务器宕机丢失1秒内的数据。

	使用redo log的优势：redo log的写入为顺序写，数据存储为随机写，顺序写效率较高；redo log仅记录变更数据及其页号和偏移，数据量小，数据存储按页写入，固定16K数据量大，综合上述两点redo log记录变更比直接写库效率高，可以保证及时写入，并发能力强。

	

	③ bin log(二进制日志)——数据备份

	bin log是记录Mysql数据逻辑变更的日志，由server层记录，使用二进制存储数据，主要用于数据备份和恢复、主从同步等。bin log持久化时同样为顺序写入，提升效率。bin log包含三种格式：statement、row、mixed。

	statement基于sql语句记录数据变更，不必记录每一行的变化，通常日志量较小，但如果sql语句中出现特定的函数，如时间函数，则statment方式会失效。

	row基于数据行记录数据变更，bin log不保存上下文信息，直接记录每一行的变更，不受制于函数功能限制，但可能会产生较多日志。

	mixed方式为上述二者的折中，普通语句使用statment方式记录，特殊函数等使用row方式记录，兼顾准确性和较小的数据量。

	在Mysql运行过程中，bin log会首先写入bin log cache中，再统一写入bin log完成日志持久化。具体持久化cache的时机由sync_binlog参数控制，参数取值：0，1，N。

	取0时，每次事务提交仅写入缓存，具体写入bin log的时机由系统决定。

	取1时，每次事务提交都将缓存写入bin log。

	取n时，缓存中包含n个事务的提交数据后，将缓存数据写入bin log。N值越大性能开销越低，但一旦宕机数据丢失也越大。

	参考：

	https://cloud.tencent.com/developer/article/2220871

	https://zhuanlan.zhihu.com/p/609972086





JDB，Java Debugger，JDK自带的命令行调试工具
jdb有两种启动方式(以Demo.class为例)：

	① 直接开启一个新的JVM进程进行调试：jdb Demo

	② 先开启一个待调试的JVM进程，再对该进程进行调试，远程调试通常使用这种方式：

	开启待调试JVM进程：java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=1044 -classpath . Demo

	开启调试：jdb -attach 8000 -sourcepath /Users/didi/JavaProject

	

	基本操作：

	stop in Demo.main 为Demo类的Main方法打断点

	stop at Demo.main:15 在Demo类的Main方法第15行打断点

	clear 查看已有断点

	locals 查看本地变量

	dump a 查看变量a的值

	list 查看源码

	next 单步执行，执行方法会直接返回结果

	step 单步执行，若是方法会进入方法

	step up 执行当前方法，直到返回

	cont 从断点处继续执行

	exit(quit) 结束程序退出调试



PDB，Python Debugger，python命令行调试工具
开启调试：python -m pdb target.py

	开启调试后看到(Pdb)即说明python解释器以调试状态运行程序，这时候程序会暂停在第一行依次执行整个target.py程序。

	基本操作：

	break(b) 10 在target.py的第10行打一个断点

	list(l) 查看当前代码段

	next(n) 单步执行

	step(s) 进入函数

	continue(c) 继续执行至下一处断点

	return(r) 执行至当前函数直至返回

	p x 打印x的值

	exit(q) 退出程序

	参考：https://blog.csdn.net/qq_43799400/article/details/122582895



WebSocket原理
背景：

	HTTP协议存在一个缺陷，通信仅能由客户端发起，客户端发起一个request，服务端返回一个response，req和rsp一一对应。若服务器需要向客户端推送消息，只能由客户端不断轮询请求，这种方式效率较低，服务器需要维持大量连接，非常浪费资源。WebSocket实现了长时间维护一个连接，客户端和服务端能够自由发起通信，传输大量数据。



	WebSocket是建立在TCP协议上的全双工通信协议，工作在应用层，允许服务端主动向客户端推送数据，作为对于HTTP协议在持久通信能力上的补充。WebSocket对于HTTP兼容性良好，其默认工作在80和443(wss)端口上，并且使用HTTP协议建立通信连接。

	优势：

	① 服务端可以向客户端推送消息

	② 数据格式轻量，通信高效，开销较小；

	③ 没有同源限制，客户端可以与任意服务器通信；

	④ 与HTTP协议兼容良好，默认端口相同

	流程：

	① 运行WebSocket协议的客户端和服务器端首先以三报文握手建立TCP连接；

	② 建立连接后，客户端使用HTTP协议向服务端传送自身支持的WebSocket版本号等信息，服务端同样以HTTP协议应答客户端的消息，建立WebSocket通信连接；

	③ WebSocket通信连接后，数据通过TCP协议进行传播，不在依靠HTTP协议。



什么是同源策略？如何解决跨域问题？
同源策略

	同源策略是一种重要的浏览器安全策略，其规定了浏览器仅能从同源的主机获取信息，限制了非同源URL之间的数据访问。同源是指URL中(协议、主机号、端口)构成的三元组相同。注意：浏览器允许发起跨域请求，也能接受跨域响应，但响应数据会被拦截，页面无法获取。

	跨域

	跨域是指浏览器端的AURL.html页面访问BURL资源，AURL与BURL不同源，因此浏览器依照同源策略拒绝数据交互。

	解决跨域的方法：

	① JSONP：前端通过<script>标签内容不受同源策略限制的特点，通过JSONP的方式从<script>中发起数据访问，构造一个回调函数将回传的数据作为回调函数的参数，使数据响应通过执行回调函数的方式在<script>中合法化，在回调函数中解析回传数据。这种方式只能实现GET方式跨域，且需要后端在回传数据的外围包裹一层回调函数，已实现<script>的正常执行。

	例如：return “callback(” + data + “)”;

	② CROS：后端通过在响应头中设置”Access-Control-Allow-Origin”字段为“*”，声明资源允许跨域访问。



Nginx
Nginx是一个轻量级的HTTP、反向代理、邮件服务器，能够为web应用提供服务器，也可以为服务集群提供反向代理服务，其内存占用低并发能力强。

	负载均衡策略：轮询策略、weight权重策略、ip哈希策略。

	轮询策略

	默认的负载均衡策略，按照请求的时间先后顺序分配不同的服务器，若服务器失效可以自动忽略。适用于服务器配置相当且服务无状态的场景。

	weight权重策略

	在轮询策略的基础上使用权重设置不同服务器的访问几率。受访几率与权重成正比，适用于服务器资源配置不均匀的情况。

	ip哈希策略

	对访问ip做哈希映射，根据哈希结果访问对应的服务器。此方式的优势在于相同ip每次都会访问相同的后台服务器。适用于有状态的服务场景，可以避免session等用户状态失效。

	

	Nginx的进程模型是其高可用性的基石。Nginx采用Master-Worker的多进程模型，其包含一个master进程用于状态监控，多个worker进程用于业务处理，多个进程相互独立，任意worker进程崩溃不会影响其他进程。启动Nginx时，该启动的进程会作为master进程，由master进程fork出来的子进程作为worker进程。

	Master进程负责管理和维护Nginx系统，确保工作进程的有效运行和配置正确应用。其主要主要职责包含三点：

	① 配置管理：读取和验证配置文件、根据配置更改启动、停止和监控worker进程。

	② 管理worker进程：按需启动或终止worker进程、配置更新时平滑地替换worker进程。

	③ 接收并处理来自系统或管理员的信号

	Worker进程负责处理具体的业务，接收连接请求并处理数据，响应请求。一个worker进程处理一个连接，各个worker之间互不干涉。通常将worker数量设置为与CPU核心数一致，一个核心绑定一个worker，以避免上下文切换的开销。worker进程主要职责如下：

	① 读写网络连接：接收来自监听端口的连接，读取请求内容，发送响应。

	② 接收master进程管理：接收master进程指令，向master进程报告状态。

	③ 资源和缓存管理：管理本地缓存和连接等资源。



	惊群现象

	惊群现象是指多个进程(或线程)等待同一个事件，当事件发生时，多个进程仅一个获取事件并进行处理，其余进程全部竞争失效重新等待。

	在Nginx中多个worker进程等待监听同一个端口下的连接，当连接来到时，多个进程会开始尝试accept连接，但仅一个会成功。为了避免惊群的发生，Nginx让多个worker进程分时监控socket避免竞争。Nginx使用一个带超时的进程锁，每个进程都尝试获取进程锁，获取后才能进入监听，锁超时后释放锁，重新尝试获取锁。





幂等的实现方式
幂等是保证接口多次操作后(误操作)，与只进行一次操作的结果是一致的，主要用于防止重试导致的操作冲突。实现幂等可以有多种方法。

	① 数据库主键/唯一性索引

	为操作结果数据库设置一个唯一性索引(或主键)，操作执行时，首先查询数据库的唯一字段，若存在则重复，返回结果；若不存在则插入一条唯一性索引数据，若成功则返回结果，若不成功则说明有并发冲突，抛出异常或重置业务。

	如果重复操作的概率较低，可以直接插入，依赖唯一性冲突实现幂等。

	② status状态机

	对于有一系列流程的业务，可以在数据库中维护一个状态status，其取值只能递增[0->1->2->3->…]通过状态代码保证单一状态只可变更一次，根据数据库更新的行数可以确定业务的执行状态。SQL如下：

	update procedure set status=2 where id=‘XXX’ and status=1;

	③ 构建防重表

	类似于①中的唯一性索引方式，但不在数据表中构建唯一性索引，单独构建一个防重表，基于防重表的唯一性冲突保证数据的单次消费。

	④ 悲观锁

	通过在数据库中加锁，保证业务的执行周期内仅能有一个线程修改数据，排除重复操作的可能性。这种方法需要使用select … for update语句为数据行上锁，且需要保证对主键或索引加锁，否则可能会升级为表锁，降低系统并发能力。

	⑤ 乐观锁

	基于递增的版本号实现乐观锁，在每次修改数据库前先查询一次对应记录的version，更新时以version的值作为判别条件，若version不变则正常修改，返回结果，若version改变则说明已经修改，不做修改直接返回。

	⑥ 分布式锁

	基于Redis或zookeeper实现分布式锁，按照流水号或UUID值设置一个分布式锁，当接收修改请求时首先根据流水号获取对应的分布式锁，正常加锁说明请求尚未执行，操作成功返回结果，若加锁失败，说明是重复请求，不做操作直接返回。





最大公约数的两种求法？
① 辗转相除法

	static int division(int a, int b ) {

    	int c = a % b;

    	while (a % b != 0) {

      		c = a % b;

      		a = b;

      		b = c;

    	}

    	return c;

  	}



	② 更相减损法

	static int subtract(int a, int b) {

    	while (a != b) {

      		if (a > b) {

        		a = a - b;

      		} else {

        		b = b - a;

      		}

    	}

    	return a;

  	}



Linux虚拟内存管理
虚拟内存管理机制需要依赖CPU中的内存管理单元(Memory Management Unit)实现，如果没有MMU，CPU执行单元发出的内存地址会直接对应物理内存地址PA(Physical Address)，当开启MMU后，CPU执行单元发出的内存地址为虚拟地址VA(Virtual Address)经过MMU转化为实际的物理地址。

	MMU将VA映射为PA是以页为单位的，通常一个页的大小为4K，这些VA到PA的映射关系由页表保存。虚拟内存管理带来了很多好处：

	① 控制物理内存访问权限。例如限制内核地址，不允许用户进程直接访问。

	② 使每个进程有独立且连续的地址空间。进程仅对虚拟内存可见，可以为每一个进程分配独立连续的虚拟空间，再通过MMU将虚拟空间映射为物理空间，尽管物理内存可能是分散的，但进程无法感知。不同进程可能访问相同的虚拟地址，映射为物理地址后是不同的，避免了内存冲突，进程之间相互独立互不干扰，提升了系统的稳定性。

	③ 便于内存分配、释放和置换(swap)。连续的VA映射为离散的PA后，一个大的虚拟内存块可以由多个小的物理块构成，提高内存利用率，便于分配和释放。此外，VA不仅可以映射为PA也可以映射为磁盘地址，因此使内存置换成为可能。

	在32位系统中，一个页表大小为4K，一个页表项占4字节，因此一个页表包含1024个页表项；在64位系统中，一个页表大小为4K，一个页表项占8字节，因此一个页表包含512个页表项。



对称加密算法和非对称加密算法
对称加密算法：DES、AES

	非对称加密算法：RSA、DSA、ECC

	散列算法：MD5、SHA1、HMAC

	通信流程：

	① 基于证书判断对方的身份是否合法

	② 使用非对称加密方式协商密钥

	③ 使用②中的密钥，基于对称加密的方式进行通信

	通信流程逻辑推演：https://zhuanlan.zhihu.com/p/43789231



Git 基本操作
拉取远程分支到本地(本地无仓库)：

	git clone -b <分支名> <仓库名>



	拉取远程分支到本地(本地有仓库无分支，新建一个本地分支)：

	git fetch	origin <远程分支名>:<本地分支名>



	拉取远程分支到本地(本地有仓库有分支，建立本地到远程的映射关系)：

	git checkout	-b	<本地分支名>		origin/<远程分支名>



强一致性和最终一致性
强一致性也称为线性一致性，定义：当一个用户访问到更新后的数据，其他任何用户都不能访问到更新前的数据。(难以实现)

	最终一致性：更新数据后，不同数据节点之间的数据同步是异步进行的，可能会出现暂时性的节点间数据不一致，经过一段时间后，数据节点间的数据会重新保持一致。

	读写一致性：为了保证同一用户的读写同步，即该用户的写入对该用户立即可见，用户写入后不能再见到写入之前版本的数据。基于单调读可以实现读写一致性，单调读有两种实现方式：

	① 时间戳：使用时间戳记录上一次写入的时间，任何时间戳前的数据都不返回给用户。

	② 读写同节点：使用hash将同一用户的操作映射至同一节点。



Stream流式编程
Stream是JDK8中出现的一种提升Collection集合类操作效率的编程方式，其使用内部迭代，而非显示迭代的方式实现元素操作。Stream配合Lambda表达式和链式编程，可以精简集合类的操作代码，提升编程效率(Debug效率降低)，在多核环境下使用并发流可以提升数据处理效率。

	流操作可以分为两种类型：

	① 中间操作，可以有多个，在流的过程中的操作，每次返回一个新的流，基于链式编程实现。典型中间操作：filter、distinct、map、reduce、peek

	② 最终操作，只能有一个，在流的最后操作，返回一个目标集合，当一个对象经过最终操作后，整个流过程即结束，无法执行进一步操作。典型的最终操作：collect、count、match、forEach

	整个流在运行到最终操作时才会开始执行迭代，。

	

	filter操作

	filter()是一个用于元素过滤的方法，其参数为一个Predicate函数式接口，Predicate接口包含一个test函数，其参数为集合对象，返回一个布尔值，判断集合内元素是否满足参数的条件。filter根据Predicate接口即可过滤元素中不符合条件的元素，保留剩余元素。filter的参数可以使用Lambda表达式传入，例如：filter(s -> s.length()>3)，可以保留集合中长度大于3的字符串。

		

	map操作

	map()方法用于将流中的元素映射为新的流中的元素，其参数为Function函数式接口，接口中包含apply()方法，参数为流中元素类型，执行给定操作后返回一个新的元素类型，构造新的流。例如：map(String::length)，将Stream<String>字符串流转换为代表字符串长度的Stream<Integer>整型流。

	

	reduce操作

	reduce是用于将元素组合起来变为一个结果的操作，其参数为BinaryOperator函数式接口，该接口继承自BiFunction，内部的apply函数传入两个参数，执行对应操作后返回结果。

	Stream内定义了两种reduce，一种为无初始值的reduce，对所有元素操作后返回一个Optional<T>类型结果，例如：Optional<Integer> ans = list.stream().reduce((a, b) -> a + b); 对list所有元素求和并返回Optional<Integer>类型结果。

	有初始值的reduce，对所有元素和初始值做操作后返回一个初始值U类型的结果，例如：int ans = lst.stream().reduce(10, (a, b) -> a + b); 初始值为10，在初始值基础上对lst中的元素求和返回ans。



	peek操作

	peek操作是一个中间操作，用于获取流中的每一个元素，并对其执行无变更的操作。其参数为Consumer函数式接口，接口内的accept()方法无返回值，因此无法修改流中元素的值，仅能执行查询操作，例如打印。peek与forEach操作类似，但forEach会终止流，而peek只是访问流的元素，并不执行额外操作，因此通常用于debug。



	forEach操作

	forEach()方法是一个返回值为void的迭代方法，其参数为Consumer函数式接口，对集合内的每一个元素执行Consumer包含的操作，并终止流。Consumer接口包含一个accpet函数，参数为集合对象，无返回值，用于对当前迭代的集合对象执行特定操作。Consumer可以通过类名::方法名的方式输入操作，例如：forEach(System.out::println)，打印集合内的对象。

	

	match操作

	match包含三种不同的操作：anyMatch、allMatch、noneMatch，三种match操作的参数都是Predicate函数式接口，anyMatch判定流中任意元素满足条件则返回true，否则返回false；allMatch判定全部元素满足条件返回true，noneMatch判定全部元素不满足条件则返回true。例如：anyMatch(s -> s.length() == 2)，字符串流中任意元素长度为2则返回true，否则返回false。

	

	collect操作

	collect方法可以将流重新收集并转化为集合类型。collect方法参数为一个Collector接口，代表目标集合的转化方法，返回一个目标集合类型。

	将List<String>转化为代表对应元素长度的List<Integer>集合：

	List<Integer> ans = strs.stream().map(String::length()).collect(Collectors.toList());

	将List<String>转化为特定的List实现类型，LinkedList::new调用LinkedList的构造函数：

	List<String> ans = strs.stream().collect(Collectors.toCollection(LinkedList::new));

	此外，也可以使用toArray()将List<String>转化为String[]:

	String[] ans = strs.stream().toArray(String[]::new);



BIO、NIO、IO多路复用、AIO
同步和异步：同步和异步是对请求方和被请求方之间的关系而言的。对同步而言，请求方发起请求后「等待」被请求方执行操作，当被请求方操作完成后，请求方继续后续任务。对异步而言，请求方发起请求后「不等待」被请求方执行操作，直接进行后续操作。

	阻塞和非阻塞：阻塞和非阻塞是对线程来说的。阻塞是指：线程发起请求后，等待IO完成时会被阻塞，释放CPU资源。非阻塞是指：线程发起请求后，不释放CPU资源(不一定等待IO完成)。

	

	BIO，同步阻塞IO

	线程发起请求后被阻塞，释放CPU资源，等待IO完成后加载数据继续执行后续任务。



	NIO，同步非阻塞IO

	线程发起请求后不被阻塞，不断轮询查看IO操作是否完成，等待IO完成后继续执行后续任务。



	IO多路复用

	IO多路复用是在NIO的基础上，维护包含多个IO状态的数据结构，使用一个线程不断轮询这些IO状态，以管理多个IO操作。多路指维护多个IO操作，复用指复用一个线程，通过这种方式实现一个线程操作多个IO，避免多线程开销。



	AIO，异步非阻塞IO

	异步IO一定是属于非阻塞的。当线程发起IO请求后获得一个标识符，继续向后执行，不阻塞；当IO完成后，触发回调函数，处理IO的结果，完成后继续运行。



逃逸分析
逃逸是指当一个对象的指针被多个方法、多个线程或全局变量引用时，称这个对象为逃逸对象。逃逸分析是分析对象指针的动态引用范围的分析过程，其属于编译优化的指针分析过程。逃逸分析通常在JVM运行期间实现。

	逃逸方式：

	① 方法逃逸：方法内定义的局部变量被外部方法引用，例如作为参数传递给其他方法，或作为结果返回给其他方法，都将造成对象逃逸。

	② 线程逃逸：本线程运行的方法的对象被其他线程访问，也将造成对象逃逸。

	逃逸分析的作用：

	① 栈上分配：通过逃逸分析可以确定一个对象是否仅包含于当前方法中(局部变量)，对于这种未逃逸的对象可以直接将其内存分配于栈帧中，无需入堆，这样当方法运行结束栈帧回收对象也会被回收，减少了堆内对象的分配和销毁次数，减轻GC压力优化性能。

	② 同步消除：若类上存在同步锁，但运行时仅有一个现成访问方法，逃逸分析后会取消方法上的同步锁，提升运行效率。

	③ 标量替换：Java中基本数据类型不可再分，被称为标量，可再分的类型被称为聚合量(如对象)。若逃逸分析后判定对象不会逃逸且该对象可分解，则运行过程中可能不生成对象，直接使用标量代替对象实现原有的功能。

	注：Hotpot并未实际采用栈上分配功能，仅实现了同步消除和标量替换。



父子进程间内存共享问题
父进程fork得到子进程后，父子进程的代码段是相同的，os会将代码段设置为只读，并将其在父子进程之间共享。

	对于堆栈和数据段，父子进程之间需要相互独立。Linux采用写时复制的技术，子进程创建完成后仅持有一个新建的页表，页表映射的物理内存与父进程一致。对于同一个内存页，父子进程相同时，父子进程的页表指向同一个物理地址。当页内出现修改时，内核会为将需要修改的页创建拷贝，再将修改该页的进程页表指向新的拷贝页，避免冲突。